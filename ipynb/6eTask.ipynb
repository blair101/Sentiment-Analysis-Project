{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "def load_data_from_json(file_name):\n",
    "    file_data = open(file_name)\n",
    "    \n",
    "    list_data = []\n",
    "    while 1:\n",
    "        line = file_data.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        sample_dict = ast.literal_eval(str(line).replace('\\n', ''))\n",
    "        list_data.append(sample_dict)\n",
    "    df = pd.DataFrame(list_data)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_train = load_data_from_json('../data/train.json')\n",
    "x_train,y_train = df_train['sentence'],df_train['label']\n",
    "\n",
    "\n",
    "df_dev = load_data_from_json('../data/dev.json')\n",
    "x_dev,y_dev = df_dev['sentence'],df_dev['label']\n",
    "\n",
    "\n",
    "df_test = load_data_from_json('../data/test.json')\n",
    "x_test,y_test = df_test['sentence'],df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "\n",
    "vectorizer_word = TfidfVectorizer(max_features=40000,\n",
    "                                  min_df=5,\n",
    "                                  max_df=0.5,\n",
    "                                  analyzer='word',\n",
    "                                  stop_words='english',\n",
    "                                  ngram_range=(1, 2))\n",
    "\n",
    "vectorizer_word.fit(x_train)\n",
    "\n",
    "tfidf_matrix_word_train = vectorizer_word.transform(x_train)\n",
    "tfidf_matrix_word_dev = vectorizer_word.transform(x_dev)\n",
    "tfidf_matrix_word_test = vectorizer_word.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 21 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='sag',\n",
       "          tol=0.0001, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_word = LogisticRegression(solver='sag', verbose=2)\n",
    "lr_word.fit(tfidf_matrix_word_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7385416666666667\n",
      "0.7401500938086304\n"
     ]
    }
   ],
   "source": [
    "y_pred_word_dev = lr_word.predict(tfidf_matrix_word_dev)\n",
    "print(accuracy_score(y_dev, y_pred_word_dev))\n",
    "\n",
    "y_pred_word_test = lr_word.predict(tfidf_matrix_word_test)\n",
    "print(accuracy_score(y_test, y_pred_word_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8636), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 21 epochs took 0 seconds\n",
      "0.7552083333333334\n",
      "0.7570356472795498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm,tqdm_notebook\n",
    "vectorizer_char = TfidfVectorizer(max_features=40000,\n",
    "                                  min_df=5,\n",
    "                                  max_df=0.5,\n",
    "                                  analyzer='char',\n",
    "                                  ngram_range=(1, 4))\n",
    "\n",
    "vectorizer_char.fit(tqdm_notebook(x_train));\n",
    "\n",
    "tfidf_matrix_char_train = vectorizer_char.transform(x_train)\n",
    "tfidf_matrix_char_dev = vectorizer_char.transform(x_dev)\n",
    "tfidf_matrix_char_test = vectorizer_char.transform(x_test)\n",
    "\n",
    "\n",
    "lr_char = LogisticRegression(solver='sag', verbose=2)\n",
    "lr_char.fit(tfidf_matrix_char_train, y_train)\n",
    "\n",
    "y_pred_char_dev = lr_char.predict(tfidf_matrix_char_dev)\n",
    "print(accuracy_score(y_dev, y_pred_char_dev))\n",
    "\n",
    "y_pred_char_test = lr_char.predict(tfidf_matrix_char_test)\n",
    "print(accuracy_score(y_test, y_pred_char_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 24 epochs took 1 seconds\n",
      "0.7625\n",
      "0.775797373358349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "tfidf_matrix_word_char_train = hstack((tfidf_matrix_word_train, tfidf_matrix_char_train))\n",
    "tfidf_matrix_word_char_dev = hstack((tfidf_matrix_word_dev, tfidf_matrix_char_dev))\n",
    "tfidf_matrix_word_char_test = hstack((tfidf_matrix_word_test, tfidf_matrix_char_test))\n",
    "\n",
    "\n",
    "lr_word_char = LogisticRegression(solver='sag', verbose=2)\n",
    "lr_word_char.fit(tfidf_matrix_word_char_train, y_train)\n",
    "\n",
    "y_pred_word_char_dev = lr_word_char.predict(tfidf_matrix_word_char_dev)\n",
    "print(accuracy_score(y_dev, y_pred_word_char_dev))\n",
    "\n",
    "\n",
    "y_pred_word_char_test = lr_word_char.predict(tfidf_matrix_word_char_test)\n",
    "print(accuracy_score(y_test, y_pred_word_char_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Input, Dense, Embedding, Conv1D, Conv2D, MaxPooling1D, MaxPool2D\n",
    "from keras.layers import Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import SpatialDropout1D, concatenate\n",
    "from keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "\n",
    "MAX_NB_WORDS = 40000\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(list(x_train)+list(x_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = list(x_train)+list(x_dev)\n",
    "data_all_lens = [len(str(data_i).split()) for data_i in data_all  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/blair/.pyenv/versions/aic/lib/python3.5/site-packages/matplotlib/axes/_axes.py:6521: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  alternative=\"'density'\", removal=\"3.1\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.hist(data_all_lens, bins=100, range=[0, 100], normed=True, label='data_all')\n",
    "plt.title('words count in text', fontsize=15)\n",
    "plt.legend()\n",
    "plt.xlabel('Number of words', fontsize=15)\n",
    "plt.ylabel('Probability', fontsize=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(x_train)\n",
    "dev_sequences = tokenizer.texts_to_sequences(x_dev)\n",
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "\n",
    "MAX_LENGTH = 50\n",
    "padded_train_sequences = pad_sequences(train_sequences, maxlen=MAX_LENGTH)\n",
    "padded_dev_sequences = pad_sequences(dev_sequences, maxlen=MAX_LENGTH)\n",
    "padded_test_sequences = pad_sequences(test_sequences, maxlen=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8636, 50)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_train_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_rnn_model():\n",
    "    embedding_dim = 300\n",
    "    embedding_matrix = np.random.random((MAX_NB_WORDS, embedding_dim))\n",
    "\n",
    "    inp = Input(shape=(MAX_LENGTH,))\n",
    "    \n",
    "    x = Embedding(input_dim=MAX_NB_WORDS, output_dim=embedding_dim, input_length=MAX_LENGTH,\n",
    "                  weights=[embedding_matrix], trainable=True)(inp)\n",
    "    \n",
    "    x = SpatialDropout1D(0.3)(x)\n",
    "    x = Bidirectional(GRU(100, return_sequences=True))(x)\n",
    "    \n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    \n",
    "    outp = Dense(1, activation=\"sigmoid\")(conc)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "rnn_simple_model = get_simple_rnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8636 samples, validate on 960 samples\n",
      "Epoch 1/10\n",
      "8636/8636 [==============================] - 27s 3ms/step - loss: 0.7044 - acc: 0.5139 - val_loss: 0.6811 - val_acc: 0.5615\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.56146, saving model to ../model/non_embedding-weights-improvement-01-0.5615.hdf5\n",
      "Epoch 2/10\n",
      "8636/8636 [==============================] - 27s 3ms/step - loss: 0.6793 - acc: 0.5672 - val_loss: 0.6706 - val_acc: 0.5604\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.56146\n",
      "Epoch 3/10\n",
      "8636/8636 [==============================] - 29s 3ms/step - loss: 0.6576 - acc: 0.6106 - val_loss: 0.6368 - val_acc: 0.6646\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.56146 to 0.66458, saving model to ../model/non_embedding-weights-improvement-03-0.6646.hdf5\n",
      "Epoch 4/10\n",
      "8636/8636 [==============================] - 29s 3ms/step - loss: 0.6220 - acc: 0.6759 - val_loss: 0.6096 - val_acc: 0.6750\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.66458 to 0.67500, saving model to ../model/non_embedding-weights-improvement-04-0.6750.hdf5\n",
      "Epoch 5/10\n",
      "8636/8636 [==============================] - 28s 3ms/step - loss: 0.5759 - acc: 0.7255 - val_loss: 0.5770 - val_acc: 0.7052\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.67500 to 0.70521, saving model to ../model/non_embedding-weights-improvement-05-0.7052.hdf5\n",
      "Epoch 6/10\n",
      "8636/8636 [==============================] - 28s 3ms/step - loss: 0.5251 - acc: 0.7642 - val_loss: 0.5685 - val_acc: 0.6802\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.70521\n",
      "Epoch 7/10\n",
      "8636/8636 [==============================] - 31s 4ms/step - loss: 0.4654 - acc: 0.7989 - val_loss: 0.5312 - val_acc: 0.7354\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.70521 to 0.73542, saving model to ../model/non_embedding-weights-improvement-07-0.7354.hdf5\n",
      "Epoch 8/10\n",
      "8636/8636 [==============================] - 29s 3ms/step - loss: 0.4091 - acc: 0.8335 - val_loss: 0.5445 - val_acc: 0.7094\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.73542\n",
      "Epoch 9/10\n",
      "8636/8636 [==============================] - 32s 4ms/step - loss: 0.3530 - acc: 0.8608 - val_loss: 0.5203 - val_acc: 0.7302\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.73542\n",
      "Epoch 10/10\n",
      "8636/8636 [==============================] - 34s 4ms/step - loss: 0.2995 - acc: 0.8891 - val_loss: 0.5547 - val_acc: 0.7281\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.73542\n"
     ]
    }
   ],
   "source": [
    "filepath = \"../model/non_embedding-weights-improvement-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True,\n",
    " mode='max')\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "\n",
    "history = rnn_simple_model.fit(x=padded_train_sequences,\n",
    "                               y=y_train,\n",
    "                               validation_data=(padded_dev_sequences, y_dev),\n",
    "                               batch_size=batch_size,\n",
    "                               callbacks=[checkpoint],\n",
    "                               epochs=epochs,\n",
    "                               verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入rnn_simple_model中最好的一个，进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066/1066 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7204502814258912"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rnn_simple_model = load_model('../model/non_embedding-weights-improvement-07-0.7354.hdf5')\n",
    "\n",
    "y_pred_rnn_simple = best_rnn_simple_model.predict(padded_test_sequences, verbose=1, batch_size=128)\n",
    "\n",
    "y_pred_rnn_simple = pd.DataFrame(y_pred_rnn_simple, columns=['prediction'])\n",
    "\n",
    "y_pred_rnn_simple['prediction'] = y_pred_rnn_simple['prediction'].map(lambda p: 1 if p >= 0.5 else 0)\n",
    "\n",
    "y_pred_rnn_simple.to_csv('../model/y_pred_rnn_simple.csv', index=False)\n",
    "\n",
    "y_pred_rnn_simple = pd.read_csv('../model/y_pred_rnn_simple.csv')\n",
    "\n",
    "accuracy_score(y_test, y_pred_rnn_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. glove rnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18254), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_coefs(word, *arr):\n",
    "    try:\n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "embeddings_index = dict(get_coefs(*o.strip().split()) for o in tqdm_notebook(\n",
    "        open('../data/glove.840B.300d.txt')))\n",
    "\n",
    "embed_size = 300\n",
    "\n",
    "for k in tqdm_notebook(list(embeddings_index.keys())):\n",
    "    v = embeddings_index[k]\n",
    "    try:\n",
    "        if v.shape != (embed_size,):\n",
    "            embeddings_index.pop(k)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18521), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2435\n"
     ]
    }
   ],
   "source": [
    "values = list(embeddings_index.values())\n",
    "all_embs = np.stack(values)\n",
    "\n",
    "emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = MAX_NB_WORDS\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "\n",
    "oov = 0\n",
    "for word, i in tqdm_notebook(word_index.items()):\n",
    "    if i >= MAX_NB_WORDS: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        oov += 1\n",
    "\n",
    "print(oov)\n",
    "\n",
    "\n",
    "def get_rnn_model_with_glove_embeddings():\n",
    "    \n",
    "    embedding_dim = 300\n",
    "    \n",
    "    inp = Input(shape=(MAX_LENGTH,))\n",
    "    \n",
    "    x = Embedding(MAX_NB_WORDS, embedding_dim, weights=[embedding_matrix], \n",
    "input_length=MAX_LENGTH, trainable=True)(inp)\n",
    "    \n",
    "    x = SpatialDropout1D(0.3)(x)\n",
    "    x = Bidirectional(GRU(100, return_sequences=True))(x)\n",
    "    \n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    \n",
    "    outp = Dense(1, activation=\"sigmoid\")(conc)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "rnn_model_with_embeddings = get_rnn_model_with_glove_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8636 samples, validate on 960 samples\n",
      "Epoch 1/5\n",
      "8636/8636 [==============================] - 31s 4ms/step - loss: 0.0229 - acc: 0.9922 - val_loss: 1.0539 - val_acc: 0.7563\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.75625, saving model to ../model/rnn_glove_embedding-weights-improvement-01-0.7563.hdf5\n",
      "Epoch 2/5\n",
      "8636/8636 [==============================] - 30s 4ms/step - loss: 0.0201 - acc: 0.9939 - val_loss: 1.1487 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.75625\n",
      "Epoch 3/5\n",
      "8636/8636 [==============================] - 33s 4ms/step - loss: 0.0184 - acc: 0.9943 - val_loss: 1.2128 - val_acc: 0.7521\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.75625\n",
      "Epoch 4/5\n",
      "8636/8636 [==============================] - 33s 4ms/step - loss: 0.0183 - acc: 0.9934 - val_loss: 1.1407 - val_acc: 0.7594\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.75625 to 0.75938, saving model to ../model/rnn_glove_embedding-weights-improvement-04-0.7594.hdf5\n",
      "Epoch 5/5\n",
      "8636/8636 [==============================] - 33s 4ms/step - loss: 0.0149 - acc: 0.9953 - val_loss: 1.1952 - val_acc: 0.7646\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.75938 to 0.76458, saving model to ../model/rnn_glove_embedding-weights-improvement-05-0.7646.hdf5\n"
     ]
    }
   ],
   "source": [
    "filepath = \"../model/rnn_glove_embedding-weights-improvement-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 5\n",
    "\n",
    "history = rnn_model_with_embeddings.fit(x=padded_train_sequences,\n",
    "                            y=y_train,\n",
    "                            validation_data=(padded_dev_sequences, y_dev),\n",
    "                            batch_size=batch_size,\n",
    "                                        callbacks=[checkpoint],\n",
    "                                        epochs=epochs,\n",
    "                                        verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  导入 glove rnn model 中最好的一个，进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066/1066 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.799249530956848"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rnn_model_with_glove_embeddings = load_model('../model/rnn_glove_embedding-weights-improvement-01-0.7906.hdf5')\n",
    "\n",
    "y_pred_rnn_with_glove_embeddings = best_rnn_model_with_glove_embeddings.predict(\n",
    "    padded_test_sequences, verbose=1, batch_size=128)\n",
    "\n",
    "y_pred_rnn_with_glove_embeddings = pd.DataFrame(y_pred_rnn_with_glove_embeddings, columns=['prediction'])\n",
    "\n",
    "y_pred_rnn_with_glove_embeddings['prediction'] = y_pred_rnn_with_glove_embeddings['prediction'].map(lambda p:1 if p >= 0.5 else 0)\n",
    "y_pred_rnn_with_glove_embeddings.to_csv('../model/y_pred_rnn_with_glove_embeddings.csv', index=False)\n",
    "\n",
    "y_pred_rnn_with_glove_embeddings = pd.read_csv('../model/y_pred_rnn_with_glove_embeddings.csv')\n",
    "\n",
    "accuracy_score(y_test, y_pred_rnn_with_glove_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model():\n",
    "    embedding_dim = 300\n",
    "\n",
    "    filter_sizes = [2, 3, 5]\n",
    "    num_filters = 256\n",
    "    drop = 0.3\n",
    "\n",
    "    inputs = Input(shape=(MAX_LENGTH,), dtype='int32')\n",
    "    \n",
    "    embedding = Embedding(input_dim=MAX_NB_WORDS,\n",
    "                          output_dim=embedding_dim,\n",
    "                          weights=[embedding_matrix],\n",
    "                          input_length=MAX_LENGTH,\n",
    "                          trainable=True)(inputs)\n",
    "\n",
    "    reshape = Reshape((MAX_LENGTH, embedding_dim, 1))(embedding)\n",
    "    \n",
    "    conv_0 = Conv2D(num_filters,\n",
    "                    kernel_size=(filter_sizes[0], embedding_dim),\n",
    "                    padding='valid', kernel_initializer='normal',\n",
    "                    activation='relu')(reshape)\n",
    "\n",
    "    conv_1 = Conv2D(num_filters,\n",
    "                    kernel_size=(filter_sizes[1], embedding_dim),\n",
    "                    padding='valid', kernel_initializer='normal',\n",
    "                    activation='relu')(reshape)\n",
    "    conv_2 = Conv2D(num_filters,\n",
    "                    kernel_size=(filter_sizes[2], embedding_dim),\n",
    "                    padding='valid', kernel_initializer='normal',\n",
    "                    activation='relu')(reshape)\n",
    "\n",
    "    maxpool_0 = MaxPool2D(pool_size=(MAX_LENGTH - filter_sizes[0] + 1, 1),\n",
    "                          strides=(1, 1), padding='valid')(conv_0)\n",
    "\n",
    "    maxpool_1 = MaxPool2D(pool_size=(MAX_LENGTH - filter_sizes[1] + 1, 1),\n",
    "                          strides=(1, 1), padding='valid')(conv_1)\n",
    "\n",
    "    maxpool_2 = MaxPool2D(pool_size=(MAX_LENGTH - filter_sizes[2] + 1, 1),\n",
    "                          strides=(1, 1), padding='valid')(conv_2)\n",
    "    concatenated_tensor = Concatenate(axis=1)(\n",
    "        [maxpool_0, maxpool_1, maxpool_2])\n",
    "    flatten = Flatten()(concatenated_tensor)\n",
    "    dropout = Dropout(drop)(flatten)\n",
    "    output = Dense(units=1, activation='sigmoid')(dropout)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "cnn_model_multi_channel = get_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8636 samples, validate on 960 samples\n",
      "Epoch 1/10\n",
      "8636/8636 [==============================] - 37s 4ms/step - loss: 0.5116 - acc: 0.7455 - val_loss: 0.4973 - val_acc: 0.7458\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.74583, saving model to ../model/cnn-weights-improvement-01-0.7458.hdf5\n",
      "Epoch 2/10\n",
      "8636/8636 [==============================] - 39s 4ms/step - loss: 0.4835 - acc: 0.7637 - val_loss: 0.4863 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.74583 to 0.75313, saving model to ../model/cnn-weights-improvement-02-0.7531.hdf5\n",
      "Epoch 3/10\n",
      "8636/8636 [==============================] - 37s 4ms/step - loss: 0.4513 - acc: 0.7890 - val_loss: 0.4786 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.75313\n",
      "Epoch 4/10\n",
      "8636/8636 [==============================] - 38s 4ms/step - loss: 0.4292 - acc: 0.8051 - val_loss: 0.4717 - val_acc: 0.7521\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.75313\n",
      "Epoch 5/10\n",
      "8636/8636 [==============================] - 38s 4ms/step - loss: 0.4078 - acc: 0.8218 - val_loss: 0.4667 - val_acc: 0.7615\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.75313 to 0.76146, saving model to ../model/cnn-weights-improvement-05-0.7615.hdf5\n",
      "Epoch 6/10\n",
      "8636/8636 [==============================] - 46s 5ms/step - loss: 0.3912 - acc: 0.8236 - val_loss: 0.4641 - val_acc: 0.7552\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.76146\n",
      "Epoch 7/10\n",
      "8636/8636 [==============================] - 44s 5ms/step - loss: 0.3749 - acc: 0.8363 - val_loss: 0.4604 - val_acc: 0.7656\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.76146 to 0.76563, saving model to ../model/cnn-weights-improvement-07-0.7656.hdf5\n",
      "Epoch 8/10\n",
      "8636/8636 [==============================] - 40s 5ms/step - loss: 0.3552 - acc: 0.8477 - val_loss: 0.4558 - val_acc: 0.7667\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.76563 to 0.76667, saving model to ../model/cnn-weights-improvement-08-0.7667.hdf5\n",
      "Epoch 9/10\n",
      "8636/8636 [==============================] - 40s 5ms/step - loss: 0.3444 - acc: 0.8577 - val_loss: 0.4530 - val_acc: 0.7740\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.76667 to 0.77396, saving model to ../model/cnn-weights-improvement-09-0.7740.hdf5\n",
      "Epoch 10/10\n",
      "8636/8636 [==============================] - 40s 5ms/step - loss: 0.3265 - acc: 0.8672 - val_loss: 0.4503 - val_acc: 0.7708\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.77396\n"
     ]
    }
   ],
   "source": [
    "filepath = \"../model/cnn-weights-improvement-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "\n",
    "history = cnn_model_multi_channel.fit(x=padded_train_sequences,\n",
    "                                      y=y_train,\n",
    "                            validation_data=(padded_dev_sequences, y_dev),\n",
    "                                      batch_size=batch_size,\n",
    "                                      callbacks=[checkpoint],\n",
    "                                      epochs=epochs,\n",
    "                                      verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入 cnn_model 中最好的一个，进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066/1066 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.776735459662289"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_cnn_model = load_model('../model/cnn-weights-improvement-09-0.7740.hdf5')\n",
    "\n",
    "y_pred_cnn_multi_channel = best_cnn_model.predict(padded_test_sequences, verbose=1, batch_size=128)\n",
    "\n",
    "y_pred_cnn_multi_channel = pd.DataFrame(y_pred_cnn_multi_channel, columns=['prediction'])\n",
    "y_pred_cnn_multi_channel['prediction'] = y_pred_cnn_multi_channel['prediction'].map(lambda p: 1 if p >= 0.5 else 0)\n",
    "y_pred_cnn_multi_channel.to_csv('../model/y_pred_cnn_multi_channel.csv', index=False)\n",
    "\n",
    "y_pred_cnn_multi_channel = pd.read_csv('../model/y_pred_cnn_multi_channel.csv')\n",
    "accuracy_score(y_test, y_pred_cnn_multi_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rnn_cnn_model():\n",
    "    \n",
    "    embedding_dim = 300\n",
    "    \n",
    "    inp = Input(shape=(MAX_LENGTH,))\n",
    "    \n",
    "    x = Embedding(MAX_NB_WORDS, embedding_dim, weights=[embedding_matrix], \n",
    "input_length=MAX_LENGTH, trainable=True)(inp)\n",
    "    \n",
    "    x = SpatialDropout1D(0.3)(x)\n",
    "    \n",
    "    x = Bidirectional(GRU(100, return_sequences=True))(x)\n",
    "    \n",
    "    x = Conv1D(64, kernel_size=2, padding=\"valid\", kernel_initializer=\"he_uniform\")(x)\n",
    "    \n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    outp = Dense(1, activation=\"sigmoid\")(conc)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "rnn_cnn_model = get_rnn_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8636 samples, validate on 960 samples\n",
      "Epoch 1/6\n",
      "8636/8636 [==============================] - 27s 3ms/step - loss: 0.6293 - acc: 0.6467 - val_loss: 0.5179 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.74896, saving model to ../model/rcnn-drop0.2-weights-improvement-01-0.7490.hdf5\n",
      "Epoch 2/6\n",
      "8636/8636 [==============================] - 24s 3ms/step - loss: 0.4662 - acc: 0.7808 - val_loss: 0.4667 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.74896 to 0.78438, saving model to ../model/rcnn-drop0.2-weights-improvement-02-0.7844.hdf5\n",
      "Epoch 3/6\n",
      "8636/8636 [==============================] - 24s 3ms/step - loss: 0.3705 - acc: 0.8370 - val_loss: 0.4452 - val_acc: 0.7990\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.78438 to 0.79896, saving model to ../model/rcnn-drop0.2-weights-improvement-03-0.7990.hdf5\n",
      "Epoch 4/6\n",
      "8636/8636 [==============================] - 23s 3ms/step - loss: 0.2956 - acc: 0.8715 - val_loss: 0.4754 - val_acc: 0.7865\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.79896\n",
      "Epoch 5/6\n",
      "8636/8636 [==============================] - 22s 3ms/step - loss: 0.2204 - acc: 0.9104 - val_loss: 0.5008 - val_acc: 0.7896\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.79896\n",
      "Epoch 6/6\n",
      "8636/8636 [==============================] - 24s 3ms/step - loss: 0.1598 - acc: 0.9414 - val_loss: 0.5773 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.79896\n"
     ]
    }
   ],
   "source": [
    "filepath = \"../model/rcnn-weights-improvement-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n",
    "save_best_only=True, mode='max')\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 6\n",
    "\n",
    "history = rnn_cnn_model.fit(x=padded_train_sequences,\n",
    "                            y=y_train,\n",
    "                            validation_data=(padded_dev_sequences, y_dev),\n",
    "                            batch_size=batch_size,\n",
    "                            callbacks=[checkpoint],\n",
    "                            epochs=epochs,\n",
    "                            verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  导入 rnn_cnn_model 中最好的一个，进行预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test , padded_test_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066/1066 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8123827392120075"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rnn_cnn_model = load_model('../model/rcnn-weights-improvement-04-0.8167.hdf5')\n",
    "y_pred_rnn_cnn = best_rnn_cnn_model.predict(padded_test_sequences, verbose=1, batch_size=128)\n",
    "\n",
    "y_pred_rnn_cnn = pd.DataFrame(y_pred_rnn_cnn, columns=['prediction'])\n",
    "y_pred_rnn_cnn['prediction'] = y_pred_rnn_cnn['prediction'].map(lambda p: 1 if p >= 0.5 else 0)\n",
    "y_pred_rnn_cnn.to_csv('../model/y_pred_rnn_cnn.csv', index=False)\n",
    "\n",
    "y_pred_rnn_cnn = pd.read_csv('../model/y_pred_rnn_cnn.csv')\n",
    "accuracy_score(y_test, y_pred_rnn_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
